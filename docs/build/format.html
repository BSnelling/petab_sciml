<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Format · PEtab SciML extension</title><meta name="title" content="Format · PEtab SciML extension"/><meta property="og:title" content="Format · PEtab SciML extension"/><meta property="twitter:title" content="Format · PEtab SciML extension"/><meta name="description" content="Documentation for PEtab SciML extension."/><meta property="og:description" content="Documentation for PEtab SciML extension."/><meta property="twitter:description" content="Documentation for PEtab SciML extension."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">PEtab SciML extension</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">Home</a></li><li><a class="tocitem" href="tutorial.html">Tutorial</a></li><li class="is-active"><a class="tocitem" href="format.html">Format</a><ul class="internal"><li><a class="tocitem" href="#High-Level-Overview"><span>High Level Overview</span></a></li><li><a class="tocitem" href="#Neural-Network-Model-Format"><span>Neural Network Model Format</span></a></li><li><a class="tocitem" href="#Mapping-Table"><span>Mapping Table</span></a></li><li><a class="tocitem" href="#Condition-Table"><span>Condition Table</span></a></li><li><a class="tocitem" href="#parameter_table"><span>Parameter Table</span></a></li><li><a class="tocitem" href="#YAML_file"><span>Problem YAML File</span></a></li></ul></li><li><a class="tocitem" href="net_activation.html">Supported Layers and Activation Functions</a></li><li><a class="tocitem" href="test_info.html">Test Suite</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="format.html">Format</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="format.html">Format</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/sebapersson/petab_sciml" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/sebapersson/petab_sciml/blob/main/docs/src/format.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Format-Specification"><a class="docs-heading-anchor" href="#Format-Specification">Format Specification</a><a id="Format-Specification-1"></a><a class="docs-heading-anchor-permalink" href="#Format-Specification" title="Permalink"></a></h1><p>A PEtab SciML problem extends the PEtab standard version 2 to accommodate hybrid models (SciML problems) that combine data-driven (neural net) and mechanistic components. The extension introduces one new PEtab file type:</p><ol><li><strong>Neural Net File(s)</strong>: Optional YAML file(s) describing neural net model(s).</li></ol><p>It further extends the following standard PEtab files:</p><ol><li><strong>Mapping Table</strong>: Used to describe how neural network inputs and outputs map to PEtab quantities.</li><li><strong>Parameters Table</strong>: Used to describe nominal values and potential priors for initializing network parameters.</li><li><strong>Condition Table</strong>: Used to assign neural network outputs and inputs.</li><li><strong>Problem YAML File</strong>: Includes a new SciML field for neural network models and potential arrays.</li></ol><p>All other PEtab files remain unchanged. This page explains the format and options for each file that is added or modified by the PEtab SciML extension.</p><h2 id="High-Level-Overview"><a class="docs-heading-anchor" href="#High-Level-Overview">High Level Overview</a><a id="High-Level-Overview-1"></a><a class="docs-heading-anchor-permalink" href="#High-Level-Overview" title="Permalink"></a></h2><p>The main goal of the PEtab SciML extension is to enable hybrid models that combine data-driven and mechanistic components. There are three types of hybrid model considered, each specified differently:</p><ol><li><p><strong>Data-driven models in the ODE model’s right-hand side (RHS):</strong> In this scenario, the SBML file is modified during import by either replacing a derivative or setting a parameter value to a neural network output. In both cases, the neural network input and output variables (as defined in the mapping table) must be assigned in the condition table using the <code>setNetRate</code> and/or <code>setNetAssignment</code> operator types.</p></li><li><p><strong>Data-driven models in the observable function:</strong> In this scenario, the neural network output variable (as defined in the mapping table) is directly inserted in the observable formula. Meanwhile, the input variables (also defined in the mapping table) are assigned in the condition table using the <code>setNetAssignment</code> operator type.</p></li><li><p><strong>Data-driven models before the ODE model:</strong> In this scenario, the data-driven model sets constant parameters or initial values in the ODE model prior to simulation. The input variable (as defined in the mapping table) can be assigned in the parameter or condition table as a standard constant PEtab variable, and the output variables (as defined in the mapping table) are assigned via the condition table.</p></li></ol><h2 id="Neural-Network-Model-Format"><a class="docs-heading-anchor" href="#Neural-Network-Model-Format">Neural Network Model Format</a><a id="Neural-Network-Model-Format-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Network-Model-Format" title="Permalink"></a></h2><p>The neural network model format is flexible, meaning that data-driven models can be provided in any format supported by tools compatible with the PEtab SciML format (for example, <a href="https://github.com/LuxDL/Lux.jl">Lux.jl</a> in <a href="https://github.com/sebapersson/PEtab.jl">PEtab.jl</a>). Additionally, the <code>petab_sciml</code> library offers a YAML file format (see below) for neural network models, which can be imported into tools across programming languages. The reason for this flexibility in format is that, although the YAML format can accommodate many architectures, some may still be difficult to represent. Still, when possible, we recommend using the YAML format to facilitate model exchange across different software.</p><p>Regardless of the model format, to be compatible with the PEtab SciML format a neural network model must include two main parts:</p><ul><li><strong>layers</strong>: A constructor that defines the network layers, each with a unique identifier.</li><li><strong>forward</strong>: A forward pass function that, given input arguments, specifies the order of layer calls and any activation functions used and returns an array output.</li></ul><h3 id="YAML-Network-file-format"><a class="docs-heading-anchor" href="#YAML-Network-file-format">YAML Network file format</a><a id="YAML-Network-file-format-1"></a><a class="docs-heading-anchor-permalink" href="#YAML-Network-file-format" title="Permalink"></a></h3><p>The <code>petab_sciml</code> library provides a YAML file format for neural network model exchange, where layer names and argument syntax follow PyTorch conventions. Although the YAML files can be written manually, the recommended approach is to define a PyTorch <code>nn.Module</code>—using the constructor to set up the layers and the <code>forward</code> method to specify how they are invoked. For example, a simple feed-forward network can be defined as:</p><pre><code class="language-python hljs">class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.layer1 = nn.Linear(in_features=2, out_features=5)
        self.layer2 = nn.Linear(in_features=5, out_features=5)
        self.layer3 = nn.Linear(in_features=5, out_features=1)

    def forward(self, x):
        x = self.layer1(x)
        x = F.tanh(x)
        x = self.layer2(x)
        x = F.tanh(x)
        x = self.layer3(x)
        return x</code></pre><p>The corresponding YAML file can then be generated using the <code>petab_sciml</code> library:</p><pre><code class="language-python hljs"># TODO: Add when syntax is decided upon</code></pre><p>Any PyTorch-supported keyword can be supplied for each layer in the YAML file, allowing for a broad range of architectures. For example, a more complex convolutional model could be created by:</p><pre><code class="language-python hljs">class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.max_pool1 = nn.MaxPool2d((2, 2))
        self.fc1 = nn.Linear(64, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        self.flatten1 = nn.Flatten()

    def forward(self, input):
        c1 = self.conv1(input)
        s2 = self.max_pool1(c1)
        c3 = self.conv2(s2)
        s4 = self.max_pool1(c3)
        s4 = self.flatten1(s4)
        f5 = self.fc1(s4)
        f6 = self.fc2(f5)
        output = self.fc3(f6)
        return output</code></pre><p>A complete list of supported and tested layers and activation functions can be found <a href="net_activation.html#layers_activation">here</a>.</p><h3 id="hdf5_ps_structure"><a class="docs-heading-anchor" href="#hdf5_ps_structure">Neural Network Parameters</a><a id="hdf5_ps_structure-1"></a><a class="docs-heading-anchor-permalink" href="#hdf5_ps_structure" title="Permalink"></a></h3><p>All parameters for a neural network model are stored in an HDF5 file, with the file path specified in the problem <a href="format.html#YAML_file">YAML file</a>. In this file, each layer’s parameters are in a group with identifier <code>f.layerId</code>, where <code>layerId</code> is the layer’s unique identifier. More formally, an HDF5 parameter file should have the following structure for an arbitrary number of layers:</p><pre><code class="nohighlight hljs">parameters.hdf5
└───layer1 (group)
│   ├── arrayId{1}
│   └── arrayId{2}
└───layer2 (group)
    ├── arrayId{1}
    └── arrayId{2}</code></pre><p>Here, <code>arrayId</code> depends on the naming convention for parameters in each layer. For example, a PyTorch <code>linear</code> layer typically has arrays named <code>weight</code> and (optionally) <code>bias</code>. While these names are common in many layers, the actual <code>arrayId</code> depends on the layer type and the specific neural network library.</p><p>Because parameters are stored in HDF5, they are saved as arrays. The indexing convention and naming therefore depends on the model library:</p><ul><li>For neural network models in the PEtab SciML YAML format, indexing follows PyTorch conventions. Usually, users do not need to handle these details directly, as PEtab SciML tools manage them automatically. This also means that <code>arrayId</code> follows PyTorch naming convention.</li><li>For neural networks provided by another library, the indexing and <code>arrayId</code> naming follow that library’s conventions.</li></ul><h3 id="hdf5_input_structure"><a class="docs-heading-anchor" href="#hdf5_input_structure">Neural Network Input</a><a id="hdf5_input_structure-1"></a><a class="docs-heading-anchor-permalink" href="#hdf5_input_structure" title="Permalink"></a></h3><p>When network input is provided as an array via an HDF5 file (see the mapping table below), its format should be:</p><pre><code class="nohighlight hljs">input.hdf5
└───input (group)
    └─── input_array</code></pre><p>As with <a href="format.html#hdf5_ps_structure">parameters</a>, the indexing depends on the neural network library:</p><ul><li>For neural network models in the PEtab SciML format, indexing follows PyTorch conventions. For example, if the first layer is <code>Conv2d</code>, the input should be in <code>(C, W, H)</code> format, with data stored in row-major order. In general, the input should be structured to be directly compatible with PyTorch.</li><li>For neural networks provided by another library, the indexing and ordering follow the conventions of that library.</li></ul><div class="admonition is-success"><header class="admonition-header">For developers: Respect memory order</header><div class="admonition-body"><p>Tools supporting the SciML extension should, for computational efficiency, reorder input data and potential layer parameter arrays to match the memory ordering of the target language. For example, PEtab.jl converts input data to column-major order, with Julia indexing.</p></div></div><p>TODO: We will fix condition specific input in the YAML file later.</p><h2 id="Mapping-Table"><a class="docs-heading-anchor" href="#Mapping-Table">Mapping Table</a><a id="Mapping-Table-1"></a><a class="docs-heading-anchor-permalink" href="#Mapping-Table" title="Permalink"></a></h2><p>To avoid confusion regarding what a neural network ID (<code>netId</code>) refers to (e.g., parameters, inputs, etc.), <code>netId</code> is not considered a valid PEtab identifier. Consequently, every neural network input, parameter, and output must be explicitly mapped in the mapping table to a PEtab variable. In the context of the PEtab SciML extension, the relevant mapping table columns are:</p><ul><li><strong>petabEntityId [STRING]</strong>: A valid PEtab identifier that is not defined elsewhere in the PEtab problem. This identifier can be referenced in the condition, measurement, parameter, and observable tables, but not within the model itself. For neural network outputs, the PEtab identifier must be assigned in the condition table; for inputs, this is not required (see examples below).</li><li><strong>modelEntityId [STRING]</strong>: Describes the neural network entity corresponding to the <code>petabEntityId</code>. This must specify a parameter set (e.g. <code>netId.parameters</code>), an input (e.g. <code>netId.input[{n}]</code>), or an output (<code>netId.output[{n}]</code>), where <code>n</code> is the specific input or output index.</li></ul><h3 id="Network-with-Scalar-Inputs"><a class="docs-heading-anchor" href="#Network-with-Scalar-Inputs">Network with Scalar Inputs</a><a id="Network-with-Scalar-Inputs-1"></a><a class="docs-heading-anchor-permalink" href="#Network-with-Scalar-Inputs" title="Permalink"></a></h3><p>For networks with scalar inputs, the PEtab entity should be a PEtab variable. For example, assume that the network <code>net1</code> has two inputs, then a valid mapping table would be:</p><table><tr><th style="text-align: right"><strong>petabEntityId</strong></th><th style="text-align: right"><strong>modelEntityId</strong></th></tr><tr><td style="text-align: right">net1_input1</td><td style="text-align: right">net1.input[1]</td></tr><tr><td style="text-align: right">net1_input2</td><td style="text-align: right">net1.input[2]</td></tr></table><p>Scalar input variables can then be:</p><ul><li><strong>Parameters in the parameters table</strong>: These may be either estimated or constant.</li><li><strong>Parameters assigned in the condition table</strong>: More details on this option can be found in the section on the condition table.</li></ul><h3 id="Network-with-Array-Inputs"><a class="docs-heading-anchor" href="#Network-with-Array-Inputs">Network with Array Inputs</a><a id="Network-with-Array-Inputs-1"></a><a class="docs-heading-anchor-permalink" href="#Network-with-Array-Inputs" title="Permalink"></a></h3><p>Sometimes, such as with image data, a neural network requires array input. In these situations, the input should be specified as an HDF5 file (for file structure <a href="format.html#hdf5_input_structure">here</a>), which is mapped to a suitable PEtab ID in the <a href="format.html#YAML_file">YAML file</a>. This identifier variable is then mapped to a PEtab variable in the mapping table. For example, given that <code>net1</code> has a file input, a valid mapping table would be:</p><table><tr><th style="text-align: right"><strong>petabEntityId</strong></th><th style="text-align: right"><strong>modelEntityId</strong></th></tr><tr><td style="text-align: right">net1<em>input</em>file</td><td style="text-align: right">net1.input</td></tr></table><p>Where <code>net1_input_file</code> has been specified in the problem <a href="format.html#YAML_file">YAML file</a>.</p><p>When multiple simulation conditions each require a different neural network array input, the mapping table should map the input to a PEtab variable (for example, <code>net1\_input</code>):</p><table><tr><th style="text-align: right"><strong>petabEntityId</strong></th><th style="text-align: right"><strong>modelEntityId</strong></th></tr><tr><td style="text-align: right">net1_input</td><td style="text-align: right">net1.input</td></tr></table><p>This variable (here <code>net1_input</code>) is then assigned to specific input file variables (e.g. <code>net1\_input_cond1</code> and <code>net1\_input_cond2</code>) via the condition table using the <code>setValue</code> operator type. For a full example of a valid PEtab problem with array inputs, see [ADD].</p><p>TODO: Will fix an input format later.</p><h3 id="Network-with-Multiple-Input-Arguments"><a class="docs-heading-anchor" href="#Network-with-Multiple-Input-Arguments">Network with Multiple Input Arguments</a><a id="Network-with-Multiple-Input-Arguments-1"></a><a class="docs-heading-anchor-permalink" href="#Network-with-Multiple-Input-Arguments" title="Permalink"></a></h3><p>Sometimes a neural network model’s forward function has multiple input arguments. When the <code>netId.input[{n}]</code> notation is used in the mapping table it is assumed that there is only one input argument. Therefore, when there are multiple input arguments, the <code>netId.inputArg{n}</code> notation should be used. For example, if there are two input arguments, each taking a scalar value, a valid mapping table would be:</p><table><tr><th style="text-align: right"><strong>petabEntityId</strong></th><th style="text-align: right"><strong>modelEntityId</strong></th></tr><tr><td style="text-align: right">net1_arg1</td><td style="text-align: right">net1.inputArg1[1]</td></tr><tr><td style="text-align: right">net1_arg2</td><td style="text-align: right">net1.inputArg2[1]</td></tr></table><h3 id="Network-Observable-Formula-Output"><a class="docs-heading-anchor" href="#Network-Observable-Formula-Output">Network Observable Formula Output</a><a id="Network-Observable-Formula-Output-1"></a><a class="docs-heading-anchor-permalink" href="#Network-Observable-Formula-Output" title="Permalink"></a></h3><p>If the neural network output appears in the observable formula, the PEtab entity should be directly referenced in the observable formula. For example, given:</p><table><tr><th style="text-align: right"><strong>petabEntityId</strong></th><th style="text-align: right"><strong>modelEntityId</strong></th></tr><tr><td style="text-align: right">net1_output1</td><td style="text-align: right">net1.output[1]</td></tr></table><p>A valid entry in the observable table would be:</p><table><tr><th style="text-align: right"><strong>observableId</strong></th><th style="text-align: right"><strong>observableFormula</strong></th></tr><tr><td style="text-align: right">obs1</td><td style="text-align: right">net1_output1</td></tr></table><p>As usual, the <code>observableFormula</code> can be any valid PEtab equation, so <code>net1_output1 + 1</code> would also be valid.</p><h3 id="Network-Scalar-Output"><a class="docs-heading-anchor" href="#Network-Scalar-Output">Network Scalar Output</a><a id="Network-Scalar-Output-1"></a><a class="docs-heading-anchor-permalink" href="#Network-Scalar-Output" title="Permalink"></a></h3><p>If the output does not appear in the observable formula, the output variable should still be defined in the mapping table:</p><table><tr><th style="text-align: right"><strong>petabEntityId</strong></th><th style="text-align: right"><strong>modelEntityId</strong></th></tr><tr><td style="text-align: right">net1_output1</td><td style="text-align: right">net1.output[1]</td></tr></table><p>The output parameter (<code>net1_output1</code>) is then assigned in the condition table (see below).</p><h3 id="mapping_ps"><a class="docs-heading-anchor" href="#mapping_ps">Network Parameter Values</a><a id="mapping_ps-1"></a><a class="docs-heading-anchor-permalink" href="#mapping_ps" title="Permalink"></a></h3><p>The PEtab ID representing the parameters for a neural network model must also be assigned in the mapping table. For example, if the network is called <code>net1</code>, a valid mapping table entry would be:</p><table><tr><th style="text-align: right"><strong>petabEntityId</strong></th><th style="text-align: right"><strong>modelEntityId</strong></th></tr><tr><td style="text-align: right">net1_ps</td><td style="text-align: right">net1.parameters</td></tr></table><p>Next, <code>net1_ps</code> should be assigned properties in the <a href="format.html#parameter_table">parameter table</a>.</p><p>It is also possible to target a specific layer in the parameter table. To do so, the layer must first be mapped to a PEtab variable. For the case above, a valid mapping table to target <code>layer1</code> would be:</p><table><tr><th style="text-align: right"><strong>petabEntityId</strong></th><th style="text-align: right"><strong>modelEntityId</strong></th></tr><tr><td style="text-align: right">net1_ps</td><td style="text-align: right">net1.parameters</td></tr><tr><td style="text-align: right">net1_ps_layer1</td><td style="text-align: right">net1.parameters.layer1</td></tr></table><p>It is also possible to target parameter arrays within a layer using the notation <code>netId.layerId.arrayId</code>.</p><h3 id="Additional-Details"><a class="docs-heading-anchor" href="#Additional-Details">Additional Details</a><a id="Additional-Details-1"></a><a class="docs-heading-anchor-permalink" href="#Additional-Details" title="Permalink"></a></h3><p>Although a neural network can, in principle, accept both array and scalar inputs for a single argument, this feature is not currently tested for among tools implementing the PEtab SciML extension due to it being hard to implement. To have both scalar and array input, the neural network model should instead have multiple arguments for its forward pass function.</p><h2 id="Condition-Table"><a class="docs-heading-anchor" href="#Condition-Table">Condition Table</a><a id="Condition-Table-1"></a><a class="docs-heading-anchor-permalink" href="#Condition-Table" title="Permalink"></a></h2><p>In the PEtab SciML extension, the condition table is extended to specify how neural network outputs and, if necessary, inputs are assigned. Two new <code>operatorType</code> values are introduced to support this functionality. Similar to the the PEtab format for differentiable/algebraic targets, these <code>operatorType</code> values mean:</p><ol><li><strong>setNetRate</strong>: Assigns the rate of a species to a neural network output. Here, <code>targetValue</code> must be a neural network output and <code>targetId</code> must be a model specie.</li><li><strong>setNetAssignment</strong>: Assigns the input or output of a neural network in the ODE right-hand side (RHS) or the input in the observable formula.<ul><li>Input Case: <code>targetId</code> is a neural network input, and <code>targetValue</code> can be any valid PEtab math expression that references model variables.</li><li>Output Case: <code>targetId</code> is a non-estimated ODE model parameter, and <code>targetValue</code> is a neural network output. This is used to assign a neural network output in the ODE model RHS.</li></ul></li></ol><div class="admonition is-category-warn"><header class="admonition-header">Model structure altering conditions</header><div class="admonition-body"><p>When <code>setNetRate</code> or <code>setNetAssignment</code> are used, during model import the generated model structure or observable formula is altered, basically a neural-network is inserted into the generated functions. Therefore, as unique model structures per condition are not supported in most PEtab tools, the same <code>setNetAssignment</code> or <code>setNetRate</code> assignment must be set per condition.</p></div></div><h3 id="Assigning-Neural-Network-Output"><a class="docs-heading-anchor" href="#Assigning-Neural-Network-Output">Assigning Neural Network Output</a><a id="Assigning-Neural-Network-Output-1"></a><a class="docs-heading-anchor-permalink" href="#Assigning-Neural-Network-Output" title="Permalink"></a></h3><p>To set a <strong>constant model parameter value</strong> before model simulations, the <code>setValue</code> operator type should be used. For example, if parameter <code>p</code> is determined by <code>net1_output1</code> (mapped to a neural network output in the mapping table), a valid condition table entry is:</p><table><tr><th style="text-align: right"><strong>conditionId</strong></th><th style="text-align: right"><strong>operatorType</strong></th><th style="text-align: right"><strong>targetId</strong></th><th style="text-align: right"><strong>targetValue</strong></th></tr><tr><td style="text-align: right">cond1</td><td style="text-align: right">setValue</td><td style="text-align: right">p</td><td style="text-align: right">net1_output1</td></tr></table><p>Note that this specification allows for condition-specific assignments. For example, <code>net1_output1</code> could target a different parameter in another condition or multiple model parameters in the same condition.</p><p>To set an <strong>initial value</strong>, the <code>setInitial</code> operator type should be used. For example, if the initial value of species <code>X</code> comes from <code>net1_output1</code>, a valid condition table entry is:</p><table><tr><th style="text-align: right"><strong>conditionId</strong></th><th style="text-align: right"><strong>operatorType</strong></th><th style="text-align: right"><strong>targetId</strong></th><th style="text-align: right"><strong>targetValue</strong></th></tr><tr><td style="text-align: right">cond1</td><td style="text-align: right">setInitial</td><td style="text-align: right">X</td><td style="text-align: right">net1_output1</td></tr></table><p>To set a <strong>model derivative</strong>, the <code>setNetRate</code> operator type should be used. For example, if the rate of species <code>X</code> is given by <code>net1_output1</code>, a valid condition table entry is:</p><table><tr><th style="text-align: right"><strong>conditionId</strong></th><th style="text-align: right"><strong>operatorType</strong></th><th style="text-align: right"><strong>targetId</strong></th><th style="text-align: right"><strong>targetValue</strong></th></tr><tr><td style="text-align: right">cond1</td><td style="text-align: right">setNetRate</td><td style="text-align: right">X</td><td style="text-align: right">net1_output1</td></tr></table><p>To alter the <strong>ODE RHS</strong>, the <code>setNetAssignment</code> operator type should be used. For example, if an ODE model parameter <code>p</code> should be given by <code>net1_output1</code>, a valid condition table entry is:</p><table><tr><th style="text-align: right"><strong>conditionId</strong></th><th style="text-align: right"><strong>operatorType</strong></th><th style="text-align: right"><strong>targetId</strong></th><th style="text-align: right"><strong>targetValue</strong></th></tr><tr><td style="text-align: right">cond1</td><td style="text-align: right">setNetAssignment</td><td style="text-align: right">p</td><td style="text-align: right">net1_output1</td></tr></table><h3 id="Assigning-Neural-Network-Input"><a class="docs-heading-anchor" href="#Assigning-Neural-Network-Input">Assigning Neural Network Input</a><a id="Assigning-Neural-Network-Input-1"></a><a class="docs-heading-anchor-permalink" href="#Assigning-Neural-Network-Input" title="Permalink"></a></h3><p>When a neural network sets a <strong>constant model parameter value or initial value</strong>, its input variable (as specified in the mapping table) is a standard PEtab variable. If that input variable is not defined in the parameter table, it should be assigned using the <code>setValue</code> operator type.</p><p>When a neural network sets <strong>a model derivative or alters the ODE RHS</strong>, the input typically depends on model entities. Therefore, the input variable should be assigned using the <code>setNetAssignment</code> operator. For example, if neural network input <code>net1_input1</code> is given by specie <code>X</code>, a valid condition table is:</p><table><tr><th style="text-align: right"><strong>conditionId</strong></th><th style="text-align: right"><strong>operatorType</strong></th><th style="text-align: right"><strong>targetId</strong></th><th style="text-align: right"><strong>targetValue</strong></th></tr><tr><td style="text-align: right">cond1</td><td style="text-align: right">setNetAssignment</td><td style="text-align: right">net_input1</td><td style="text-align: right">X</td></tr></table><p>Note, to ensure correct mapping, <code>setNetAssignment</code> must always be used for inputs when the neural network is part of the ODE RHS or observable formula.</p><h3 id="operatorType-Defines-Hybrid-Model-Type"><a class="docs-heading-anchor" href="#operatorType-Defines-Hybrid-Model-Type"><code>operatorType</code> Defines Hybrid Model Type</a><a id="operatorType-Defines-Hybrid-Model-Type-1"></a><a class="docs-heading-anchor-permalink" href="#operatorType-Defines-Hybrid-Model-Type" title="Permalink"></a></h3><p>The condition table and mapping table together specify where a neural network model is located in a PEtab SciML problem. In particular:</p><ul><li>If all inputs use <code>setNetAssignment</code> and all outputs use either <code>setNetRate</code> or <code>setNetAssignment</code>, the neural network appears in the ODE RHS.</li><li>If all inputs use <code>setNetAssignment</code> and no outputs appear in the condition table, the neural network is part of the observable formula (note that the output variable must be referenced in the observable table).</li><li>If no inputs use <code>setNetAssignment</code> and all outputs use either <code>setValue</code> or <code>setInitial</code>, the neural network sets model parameters or initial values before the simulation.</li></ul><p>All other combinations are disallowed because they generally do not make sense in a PEtab context. For example, if inputs use <code>setNetAssignment</code> and outputs use <code>setValue</code>, parameter values prior to simulation would be set via an assignment rule consisting of model equations, which is not permitted in PEtab as assignment rules might be time-dependent. Moreover, if a parameter is to be set via an assignment rule, this should already be coded in the model. Implementations must ensure that the input combinations in the condition table are valid.</p><h2 id="parameter_table"><a class="docs-heading-anchor" href="#parameter_table">Parameter Table</a><a id="parameter_table-1"></a><a class="docs-heading-anchor-permalink" href="#parameter_table" title="Permalink"></a></h2><p>The parameter table follows the same format as in PEtab version 2, with a subset of fields extended to accommodate neural network parameters and new <code>initializationPriorType</code> values for neural network-specific initialization. A general overview of the parameter table is available in the PEtab documentation; here, the focus is on extensions relevant to the SciML extension.</p><h3 id="Detailed-Field-Description"><a class="docs-heading-anchor" href="#Detailed-Field-Description">Detailed Field Description</a><a id="Detailed-Field-Description-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-Field-Description" title="Permalink"></a></h3><ul><li><strong>parameterId [String]</strong>: Identifies the neural network or a specific layer/parameter array. The target of the <code>parameterId</code> must be assigned via the <a href="format.html#mapping_ps">mapping table</a>. When parsing, deeper nested levels (e.g., <code>netId.layerId</code>) have precedence for nominal values, priors, etc.</li><li><strong>nominalValue [String \| NUMERIC]</strong>: Specifies neural network nominal values. This can be:<ul><li>A PEtab variable that via the problem <a href="format.html#YAML_file">YAML file</a> maps to an HDF5 file with the required <a href="format.html#hdf5_ps_structure">structure</a>. If no file exists at the given path when the problem is imported and the parameters are set to be estimated, a file is created with randomly sampled values.</li><li>A numeric value applied to all parameters under <code>parameterId</code>.</li></ul></li><li><strong>estimate [0 \| 1]</strong>: Indicates whether the parameters are estimated (<code>1</code>) or fixed (<code>0</code>). This must be consistent across layers. For example, if <code>netId</code> has <code>estimate = 0</code>, then potential layer rows must also be <code>0</code>. In other words, freezing individual network parameters is not allowed.</li><li><strong>initializationPriorType [String, OPTIONAL]</strong>: Specifies the prior used for sampling initial values before parameter estimation. In addition to the PEtab-supported priors [ADD], the SciML extension supports the following standard neural network initialization priors:<ul><li><a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_"><code>kaimingUniform</code></a> (default) — with <code>gain</code> as <code>initializationPriorParameters</code> value.</li><li><a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_"><code>kaimingNormal</code></a> — with <code>gain</code> as <code>initializationPriorParameters</code> value.</li><li><a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_uniform_"><code>xavierUniform</code></a> — with <code>gain</code> as <code>initializationPriorParameters</code> value.</li><li><a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_normal_"><code>xavierNormal</code></a> — with <code>gain</code> as <code>initializationPriorParameters</code> value.</li></ul></li></ul><h3 id="Different-Priors-for-Different-Layers"><a class="docs-heading-anchor" href="#Different-Priors-for-Different-Layers">Different Priors for Different Layers</a><a id="Different-Priors-for-Different-Layers-1"></a><a class="docs-heading-anchor-permalink" href="#Different-Priors-for-Different-Layers" title="Permalink"></a></h3><p>Different layers can have distinct initialization prior parameters. For example, consider a neural-network model <code>net1</code> where <code>layer1</code> and <code>layer2</code> require different <code>initializationPriorParameters</code> because they use different activation functions that need distinct <a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.calculate_gain">gain</a> values for the <code>kaimingUniform</code> prior. A valid parameter table would be:</p><table><tr><th style="text-align: right"><strong>parameterId</strong></th><th style="text-align: right"><strong>parameterScale</strong></th><th style="text-align: right"><strong>lowerBound</strong></th><th style="text-align: right"><strong>upperBound</strong></th><th style="text-align: right"><strong>estimate</strong></th><th style="text-align: right"><strong>nominalValue</strong></th><th style="text-align: right"><strong>initializationPriorType</strong></th><th style="text-align: right"><strong>initializationPriorParameters</strong></th></tr><tr><td style="text-align: right">net1_ps</td><td style="text-align: right">lin</td><td style="text-align: right">-inf</td><td style="text-align: right">inf</td><td style="text-align: right">1</td><td style="text-align: right">net1_ps_file</td><td style="text-align: right">kaimingUniform</td><td style="text-align: right">1</td></tr><tr><td style="text-align: right">net1_layer1_ps</td><td style="text-align: right">lin</td><td style="text-align: right">-inf</td><td style="text-align: right">inf</td><td style="text-align: right">1</td><td style="text-align: right">net1_ps_file</td><td style="text-align: right">kaimingUniform</td><td style="text-align: right">1</td></tr><tr><td style="text-align: right">net1_layer2_ps</td><td style="text-align: right">lin</td><td style="text-align: right">-inf</td><td style="text-align: right">inf</td><td style="text-align: right">1</td><td style="text-align: right">net1_ps_file</td><td style="text-align: right">kaimingUniform</td><td style="text-align: right">5/3</td></tr></table><p>Where <code>parameterId</code> are assumed to have been properly assigned in the <a href="format.html#mapping_ps">mapping table</a>. In this example, each layer references the same file variable for <code>nominalValue</code>. This means the layers obtain their values from the specified file. Unless a numeric value is provided for <code>nominalValue</code>, referring to the same file is required, since all neural network parameters should be collected in a single HDF5 file following the structure described <a href="format.html#hdf5_ps_structure">here</a>.</p><p>It is also possible to specify different priors for different parameter arrays within a layer. For example, to use different priors for the weights and bias in <code>layer1</code> of <code>net1</code> (assuming a <code>linear</code> layer), a valid parameter table would be:</p><table><tr><th style="text-align: right"><strong>parameterId</strong></th><th style="text-align: right"><strong>parameterScale</strong></th><th style="text-align: right"><strong>lowerBound</strong></th><th style="text-align: right"><strong>upperBound</strong></th><th style="text-align: right"><strong>estimate</strong></th><th style="text-align: right"><strong>nominalValue</strong></th><th style="text-align: right"><strong>initializationPriorType</strong></th><th style="text-align: right"><strong>initializationPriorParameters</strong></th></tr><tr><td style="text-align: right">net1_ps</td><td style="text-align: right">lin</td><td style="text-align: right">-inf</td><td style="text-align: right">inf</td><td style="text-align: right">1</td><td style="text-align: right">net1_ps_file</td><td style="text-align: right">kaimingUniform</td><td style="text-align: right">1</td></tr><tr><td style="text-align: right">net1_layer1_weight</td><td style="text-align: right">lin</td><td style="text-align: right">-inf</td><td style="text-align: right">inf</td><td style="text-align: right">1</td><td style="text-align: right">net1_ps_file</td><td style="text-align: right">kaimingUniform</td><td style="text-align: right">1</td></tr><tr><td style="text-align: right">net1_layer1_bias</td><td style="text-align: right">lin</td><td style="text-align: right">-inf</td><td style="text-align: right">inf</td><td style="text-align: right">1</td><td style="text-align: right">net1_ps_file</td><td style="text-align: right">kaimingNormal</td><td style="text-align: right">5/3</td></tr></table><h3 id="Bounds-for-neural-net-parameters"><a class="docs-heading-anchor" href="#Bounds-for-neural-net-parameters">Bounds for neural net parameters</a><a id="Bounds-for-neural-net-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Bounds-for-neural-net-parameters" title="Permalink"></a></h3><p>Bounds can be specified for an entire network or its nested levels. However, it should be noted that most optimization algorithms used for neural networks, such as ADAM, do not support parameter bounds in their standard implementation.</p><h2 id="YAML_file"><a class="docs-heading-anchor" href="#YAML_file">Problem YAML File</a><a id="YAML_file-1"></a><a class="docs-heading-anchor-permalink" href="#YAML_file" title="Permalink"></a></h2><p>The PEtab problem YAML file follows the PEtab version 2 format, except that a mapping table is now required (it is optional in the standard). It also includes an extension section for specifying neural network YAML files, as well as any files for neural network parameters and/or inputs:</p><pre><code class="language-yaml hljs">extensions:
  petab_sciml:
    netId1:
      location: file_path1.yaml
    netId2:
      location: file_path2.yaml
    array_files:
      netId1_input:
        location: netId1_input.hdf5
        language: hdf5        
      netId1_ps:
        location: netId1_ps.hdf5
        language: hdf5        </code></pre><p>Here, <code>netId1</code> and <code>netId2</code> are the IDs of the neural network models, and <code>net1_input</code> and <code>net1_ps</code> corresponding to array files that can be used in the PEtab tables. In this case, <code>net1_input</code> would be used in the mapping table for <code>netId1</code>’s input, while <code>netId1_ps</code> would be the <code>nominalValue</code> in the parameter table.</p><p>If the neural network is provided in another format—typically one specific to a certain implementation—the neural network library should be provided to inform users which library is used. For example, when using Lux.jl in Julia, a valid file would be:</p><pre><code class="language-yaml hljs">extensions:
  petab_sciml:
    netId1:
      library: Lux.jl
    netId2:
      library: Lux.jl</code></pre><p>It is then up to the specific implementation to provide the neural network model during import of the PEtab problem.</p><p>Any number of neural networks can be specified. For example, for a model with a single neural network with ID <code>net1</code>, a valid YAML file would be:</p><pre><code class="language-yaml hljs">format_version: 2
problems:
  - model_files:
      model_sbml:
        location: model.xml
        language: sbml
    measurement_files:
      - measurements.tsv
    observable_files:
      - observables.tsv
    condition_files:
      - conditions.tsv
    mapping_files:
      - mapping_table.tsv
parameter_file: parameters.tsv
extensions:
  petab_sciml:
    net1:
      location: net1.yaml
    array_files:
      net1_ps:
        location: net1_ps.hdf5
        language: hdf5        </code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="tutorial.html">« Tutorial</a><a class="docs-footer-nextpage" href="net_activation.html">Supported Layers and Activation Functions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Wednesday 26 February 2025 09:50">Wednesday 26 February 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
