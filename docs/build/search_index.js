var documenterSearchIndex = {"docs":
[{"location":"net_activation.html#layers_activation","page":"Supported Layers and Activation Functions","title":"Supported Layers and Activation Functions","text":"","category":"section"},{"location":"net_activation.html","page":"Supported Layers and Activation Functions","title":"Supported Layers and Activation Functions","text":"The PEtab SciML neural network model YAML format supports numerous standard neural network layers and activation functions. Layer names and associated keyword arguments follow the PyTorch naming scheme. PyTorch is used because it is currently the most popular machine learning framework, and its comprehensive documentation makes it easy to look up details for any specific layer or activation function.","category":"page"},{"location":"net_activation.html","page":"Supported Layers and Activation Functions","title":"Supported Layers and Activation Functions","text":"If support is lacking for a layer or activation function you would like to see, please file an issue on GitHub.","category":"page"},{"location":"net_activation.html#Supported-Neural-Network-Layers","page":"Supported Layers and Activation Functions","title":"Supported Neural Network Layers","text":"","category":"section"},{"location":"net_activation.html","page":"Supported Layers and Activation Functions","title":"Supported Layers and Activation Functions","text":"The table below lists the supported and tested neural network layers along with links to their respective PyTorch documentation. Additionally, the table indicates which tools support each layer.","category":"page"},{"location":"net_activation.html","page":"Supported Layers and Activation Functions","title":"Supported Layers and Activation Functions","text":"layer PEtab.jl AMICI\nLinear ✔️ \nBilinear ✔️ \nFlatten ✔️ \nDropout ✔️ \nDropout1d ✔️ \nDropout2d ✔️ \nDropout3d ✔️ \nAlphaDropout ✔️ \nConv1d ✔️ \nConv2d ✔️ \nConv3d ✔️ \nConvTranspose1d ✔️ \nConvTranspose2d ✔️ \nConvTranspose3d ✔️ \nMaxPool1d ✔️ \nMaxPool2d ✔️ \nMaxPool3d ✔️ \nAvgPool1d ✔️ \nAvgPool2d ✔️ \nAvgPool3d ✔️ \nLPPool1 ✔️ \nLPPool2 ✔️ \nLPPool3 ✔️ \nAdaptiveMaxPool1d ✔️ \nAdaptiveMaxPool2d ✔️ \nAdaptiveMaxPool3d ✔️ \nAdaptiveAvgPool1d ✔️ \nAdaptiveAvgPool2d ✔️ \nAdaptiveAvgPool3d ✔️ ","category":"page"},{"location":"net_activation.html#Supported-Activation-Function","page":"Supported Layers and Activation Functions","title":"Supported Activation Function","text":"","category":"section"},{"location":"net_activation.html","page":"Supported Layers and Activation Functions","title":"Supported Layers and Activation Functions","text":"The table below lists the supported and tested activation functions along with links to their respective PyTorch documentation. Additionally, the table indicates which tools support each layer.","category":"page"},{"location":"net_activation.html","page":"Supported Layers and Activation Functions","title":"Supported Layers and Activation Functions","text":"Function PEtab.jl AMICI\nrelu ✔️ \nrelu6 ✔️ \nhardtanh ✔️ \nhardswish ✔️ \nselu ✔️ \nleaky_relu ✔️ \ngelu ✔️ \ntanhshrink ✔️ \nsoftsign ✔️ \nsoftplus ✔️ \ntanh ✔️ \nsigmoid ✔️ \nhardsigmoid ✔️ \nmish ✔️ \nelu ✔️ \ncelu ✔️ \nsoftmax ✔️ \nlog_softmax ✔️ ","category":"page"},{"location":"test_info.html#Test-Suite","page":"Test Suite","title":"Test Suite","text":"","category":"section"},{"location":"test_info.html","page":"Test Suite","title":"Test Suite","text":"Add information in the different tests.","category":"page"},{"location":"format.html#Format-Specification","page":"Format","title":"Format Specification","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"A PEtab SciML problem extends the PEtab standard version 2 to accommodate hybrid models SciML problems that combine data-driven (neural net) and mechanistic components. The extension introduces one new PEtab file type:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Neural Net File(s): YAML file(s) describing neural net model(s).","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"It further extends the following standard PEtab files:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Mapping Table: Used to describe how neural network inputs and outputs map to PEtab quantities.\nParameters Table: Used to describe nominal values and potential priors for initializing network parameters.\nCondition Table: Used to assign neural network outputs and inputs.\nProblem YAML File: Includes a new SciML field.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"All other PEtab files remain unchanged. This page explains the format and options for each file that is added or modified by the PEtab SciML extension.","category":"page"},{"location":"format.html#High-Level-Overview","page":"Format","title":"High Level Overview","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The main goal of the PEtab SciML extension is to enable hybrid models that combine data-driven and mechanistic components. There are three types of hybrid model considered, each specified differently:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Data-driven models in the ODE model’s right-hand side (RHS): In this scenario, the model file is modified during import by either replacing a derivative or assigning a parameter to a neural network output. In both cases, the neural network input and output variables (as defined in the mapping table) must be assigned in the condition table using the setNetRate and/or setNetAssignment operator types.\nData-driven models in the observable function: In this scenario, the neural network output variable (as defined in the mapping table) is directly embedded in the observable formula. Meanwhile, the input variables (also defined in the mapping table) are assigned in the condition table using the setNetAssignment operator type.\nData-driven models before the ODE model: In this scenario, the data-driven model sets constant parameters or initial values in the ODE model prior to simulation. The input variable (as defined in the mapping table) can be assigned in the parameter or condition table as a standard constant PEtab variable, and the output variables (as defined in the mapping table) are assigned via the condition table.","category":"page"},{"location":"format.html#Neural-Network-Model-Format","page":"Format","title":"Neural Network Model Format","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The neural network model format is flexible, so data-driven models can be provided in any format supported by individual tools (for example, Lux.jl in PEtab.jl). In addition, the petab_sciml library offers a YAML file format (see below) for neural network models, which can be imported into a suitable format by any tool that supports the standard. The model format is flexible because even though the YAML format can accommodate many architectures, some architectures are likely to be difficult to represent in it. However, whenever possible, we recommend using the YAML format to facilitate model exchange across different software.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Regardless of the model format, to be compatible with the PEtab SciML format a neural network model must include two main parts:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"layers: A constructor that defines the network layers, each with a unique ID.\nforward: A forward pass function that, given inputs, specifies the order of layer calls and any activation functions used.","category":"page"},{"location":"format.html#YAML-file-format","page":"Format","title":"YAML file format","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"TODO: Dilan, I will need some help from you here, link the scheme?","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"The petab_sciml library provides a YAML file format for neural network model exchange, where layer names and argument syntax follow PyTorch conventions. Although the YAML files can be written manually, the recommended approach is to define a PyTorch nn.Module—using the constructor to set up the layers and the forward method to specify how they are invoked. For example, a simple feed-forward network can be defined as:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.layer1 = nn.Linear(in_features=2, out_features=5)\n        self.layer2 = nn.Linear(in_features=5, out_features=5)\n        self.layer3 = nn.Linear(in_features=5, out_features=1)\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = F.tanh(x)\n        x = self.layer2(x)\n        x = F.tanh(x)\n        x = self.layer3(x)\n        return x","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"The corresponding YAML file can then be generated using the petab_sciml library:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"# TODO: Add","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Any PyTorch-supported keyword can be supplied for each layer in the YAML file, allowing for a broad range of architectures. For example, a more complex convolutional model might be structured as:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.max_pool1 = nn.MaxPool2d((2, 2))\n        self.fc1 = nn.Linear(64, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n        self.flatten1 = nn.Flatten()\n\n    def forward(self, input):\n        c1 = self.conv1(input)\n        s2 = self.max_pool1(c1)\n        c3 = self.conv2(s2)\n        s4 = self.max_pool1(c3)\n        s4 = self.flatten1(s4)\n        f5 = self.fc1(s4)\n        f6 = self.fc2(f5)\n        output = self.fc3(f6)\n        return output","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"A complete list of supported and tested layers and activation functions can be found here.","category":"page"},{"location":"format.html#hdf5_ps_structure","page":"Format","title":"Neural Network Parameters","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"All parameters for a neural network model are stored in an HDF5 file, with the file path specified in the mapping table. In this file, each layer’s parameters are grouped under f.layerId, where layerId is the layer’s unique identifier. More formally, an HDF5 parameter file might have the following structure for an arbitrary number of layers:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"parameters.hdf5\n└───layer1\n│   ├── arrayId{1}\n│   └── arrayId{2}\n└───layer2\n    ├── arrayId{1}\n    └── arrayId{2}","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Here, arrayId depends on the name of the parameters for a particular layer. For example, in a linear PyTorch layer, the parameter arrays are named weight and potentially bias. While these names are common for many layers, the actual arrayId depends on the layer type.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Since parameters are stored in an HDF5 format, they are saved as arrays. The indexing convention depends on the model library:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"For neural network models in the PEtab SciML format, indexing follows PyTorch conventions, meaning parameters are stored in row-major order. Typically, users do not need to manage these details manually, as PEtab SciML tools handle them automatically.\nFor neural networks provided by another library, the indexing and ordering follow the conventions of that library.","category":"page"},{"location":"format.html#hdf5_input_structure","page":"Format","title":"Neural Network Input","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"When network input is provided as an array via an HDF5 file (see the mapping table below), it should follow this format:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"input.hdf5\n└───input\n    └─── input_array","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"As with parameters, the indexing depends on the neural network library:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"For neural network models in the PEtab SciML format, indexing follows PyTorch conventions. For example, if the first layer is Conv2d, the input should be in (C, W, H) format, with data stored in row-major order. In general, the input should be structured to be directly compatible with PyTorch.\nFor neural networks provided by another library, the indexing and ordering follow the conventions of that library.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"tip: For developers: Respect memory order\nTools supporting the SciML extension should, for computational efficiency, reorder input data and potential layer parameter arrays to match the memory ordering of the target language. For example, PEtab.jl converts input data to column-major order, as used in Julia.","category":"page"},{"location":"format.html#Mapping-Table","page":"Format","title":"Mapping Table","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"To avoid confusion about what netId refers to (for example, parameters, inputs, etc...), netId is not considered a valid PEtab identifier. Consequently, every neural network input, parameter, and output must be explicitly mapped in the mapping table to a PEtab variable. In addition, to accommodate input and parameter files, the PEtab SciML extension adds a fileLocation column to the mapping table for mapping files to PEtab variables.","category":"page"},{"location":"format.html#Detailed-Field-Descriptions","page":"Format","title":"Detailed Field Descriptions","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId [STRING]: A valid PEtab identifier that is not defined elsewhere in the PEtab problem. This identifier can be referenced in the condition, measurement, parameter, and observable tables, but not within the model itself. For neural network outputs, the PEtab identifier must be assigned in the condition table; for inputs, this is not required (see examples below).\nmodelEntityId [STRING]: Describes the neural network entity corresponding to the petabEntityId. This must specify a parameter set (e.g. netId.parameters), an input (e.g. netId.input[{n}]), or an output (netId.output[{n}]), where n is the specific input or output index.\nfileLocation [STRING|Optional]: Specifies the path to the HDF5 file associated with the neural network model.","category":"page"},{"location":"format.html#Network-with-Scalar-Inputs","page":"Format","title":"Network with Scalar Inputs","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"For networks with scalar inputs, the PEtab entity should be a PEtab variable. For example, assume that the network net1 has two inputs, then a valid mapping table would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_input1 net1.input[1]\nnet1_input2 net1.input[2]","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Scalar input variables can then be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Parameters in the parameters table: These may be either estimated or constant.\nParameters assigned in the condition table: More details on this option can be found in the section on the condition table.","category":"page"},{"location":"format.html#Network-with-Array-Inputs","page":"Format","title":"Network with Array Inputs","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Sometimes, such as with image data, a neural network requires array input. In these cases, the input can be specified as an HDF5 file (see file format details here). This file is then mapped to a PEtab variable via the mapping table:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId fileLocation\nnet1_input_file  net1_input.hdf5\nnet1_input_file net1.input ","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Note that the net1.input notation implies that the entire input is provided by one variable.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"When multiple simulation conditions each require a different neural network array input, the mapping table should map to a PEtab variable (for example, net1\\_input):","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId fileLocation\nnet1_input net1.input \nnet1_input_cond1  net1_cond1.hdf5\nnet1_input_cond2  net1_cond2.hdf5","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"This variable is then assigned to specific input file variables (net1\\_input_cond1 and net1\\_input_cond2) via the condition table using the setValue operator type. For a full example of a valid PEtab problem with array inputs, see [ADD].","category":"page"},{"location":"format.html#Network-with-Multiple-Input-Arguments","page":"Format","title":"Network with Multiple Input Arguments","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Sometimes a neural network model’s forward function has multiple input arguments. Using netId.input[{n}] in the mapping table assumes there is only one input argument. Therefore, when there are multiple input arguments, the netId.inputArg{n} format should be used. For example, if there are two input arguments, each taking a scalar value, a valid mapping table would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_arg1 net1.inputArg1[1]\nnet1_arg2 net1.inputArg2[1]","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Where net1_arg1 and net1_arg2 are assumed to be assigned properly.","category":"page"},{"location":"format.html#Network-Observable-Formula-Output","page":"Format","title":"Network Observable Formula Output","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"If the neural network output appears in the observable formula, the PEtab entity should be directly referenced in the observable formula. For example, given:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_output1 net1.output[1]","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"A valid observable table would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"observableId observableFormula\nobs1 net1_output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"As usual, the observableFormula can be any valid PEtab equation, so net1_output1 + 1 would also be valid.","category":"page"},{"location":"format.html#Network-Scalar-Output","page":"Format","title":"Network Scalar Output","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"If the output does not appear in the observable, the output variable should still be defined in the mapping table:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_output1 net1.output[1]","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"The output parameter (net1_output1) is then assigned in the condition table (see below).","category":"page"},{"location":"format.html#mapping_ps","page":"Format","title":"Network Parameter Values","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Parameters for a neural network should be stored in a file (see format here) and must be assigned in the mapping table because netId is not a valid PEtab identifier. For instance, if the network is called net1, a valid mapping table would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId fileLocation\nnet1_ps net1.parameters \nnet1_ps_file  net1_ps.hdf5","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Where net1_ps_file should then be assigned as the nominal values for net1_ps in the parameter table (see below).","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"It is also possible to target a specific layer in the parameter table. To do so, the layer must first be mapped to a PEtab variable. For the case above, a valid mapping table to target layer1 would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId fileLocation\nnet1_ps net1.parameters \nnet1_ps_layer1 net1.parameters.layer1 \nnet1_ps_file  net1_ps.hdf5","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Here, net1_ps_layer1 should be assigned in the parameter table. It is also possible to target parameter arrays within a layer using the notation netId.layerId.arrayId.","category":"page"},{"location":"format.html#Additional-Details","page":"Format","title":"Additional Details","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Although a neural network can, in principle, accept both array and scalar inputs for a single argument, this feature is not currently tested for among tools implementing the PEtab SciML extension due to it being hard to implement. To have both scalar and array input, the neural network model must have multiple arguments for its forward pass function.","category":"page"},{"location":"format.html#Condition-Table","page":"Format","title":"Condition Table","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"In the PEtab SciML extension, the condition table is extended to specify how neural network outputs (and, if necessary, inputs) are assigned. Two new operatorType values are introduced to support this functionality. Following the PEtab format for differentiable/algebraic targets, these operatorType values mean:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"setNetRate: Assigns the rate of a species to a neural network output. Here, targetValue must be a neural network output and targetId must be a model specie.\nsetNetAssignment: Assigns the input or output of a neural network in the ODE right-hand side (RHS) or the input in the observable formula.\nInput Case: targetId is a neural network input, and targetValue can be any valid PEtab math expression that references model variables.\nOutput Case: targetId is a non-estimated ODE model parameter, and targetValue is a neural network output. This is used to assign a neural network output in the ODE model RHS.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"warn: Model structure altering conditions\nIWhen setNetRate or setNetAssignment are used during model import the generated model structure or observable formula is altered, basically a neural-network is inserted into the generated functions. Therefore, as unique model structures per condition are not supported in most PEtab tools, the same setNetAssignment or setNetRate assignment must be set per condition.","category":"page"},{"location":"format.html#Assigning-Neural-Network-Output","page":"Format","title":"Assigning Neural Network Output","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"To set a constant model parameter value before model simulations, the setValue operator type should be used. For example, if parameter p is determined by net1_output1 (mapped to a neural network output in the mapping table), a valid condition table entry is:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setValue p net1_output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Note that this specification allows for condition-specific assignments. For example, net1_output1 could target a different parameter in another condition or multiple model parameters in the same condition.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"To set an initial value, the setInitial operator type should be used. For example, if the initial value of species X comes from net1_output1, a valid condition table entry is:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setInitial X net1_output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"To set a model derivative, the setNetRate operator type should be used. For example, if the rate of species X is given by net1_output1, a valid condition table entry is:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setNetRate X net1_output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"To alter the ODE RHS, the setNetAssignment operator type should be used. For example, if an ODE model parameter p should be given by net1_output1, a valid condition table entry is:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setNetAssignment p net1_output1","category":"page"},{"location":"format.html#Assigning-Neural-Network-Input","page":"Format","title":"Assigning Neural Network Input","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"When a neural network sets a constant model parameter value or initial value, its input variable (as specified in the mapping table) is a standard PEtab variable. If that input variable is not defined in the parameter table, it should be assigned using the setValue operator type.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"When a neural network sets a model derivative or alters the ODE RHS, the input typically depends on model entities. Therefore, the input variable should be assigned using the setNetAssignment operator. For example, if neural network input net1_input1 is given by specie X, a valid condition table is:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setNetAssignment net_input1 X","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Note, to ensure correct mapping, setNetAssignment must always be used for inputs when the neural network is part of the ODE RHS or observable formula.","category":"page"},{"location":"format.html#operatorType-Defines-Hybrid-Model-Type","page":"Format","title":"operatorType Defines Hybrid Model Type","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The condition table and mapping table together specify where a neural network model is located in a PEtab SciML problem. In particular:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"If all inputs use setNetAssignment and all outputs use either setNetRate or setNetAssignment, the neural network appears in the ODE RHS.\nIf all inputs use setNetAssignment and no outputs appear in the condition table, the neural network is part of the observable formula (note that the output variable must be referenced in the observable table).\nIf no inputs use setNetAssignment and all outputs use either setValue or setInitial, the neural network sets model parameters or initial values before the simulation.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"All other combinations are disallowed because they generally do not make sense in a PEtab context. For example, if inputs use setNetAssignment and outputs use setValue, parameter values prior to simulation would be set via an assignment rule consisting of model equations, which is not permitted in PEtab as assignment rules might be time-dependent. Moreover, if a parameter is to be set via an assignment rule, this should already be coded in the model. Implementations must ensure that the input combinations in the condition table are valid.","category":"page"},{"location":"format.html#Parameter-Table","page":"Format","title":"Parameter Table","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The parameter table follows the same format as in PEtab version 2, with a subset of fields extended to accommodate neural network parameters and new initializationPriorType values for neural network-specific initialization. A general overview of the parameter table is available in the PEtab documentation; here, the focus is on extensions relevant to the SciML extension.","category":"page"},{"location":"format.html#Detailed-Field-Description","page":"Format","title":"Detailed Field Description","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"parameterId [String]: Identifies the neural network or a specific layer/parameter array. The target of the parameterId must be assigned via the mapping table. When parsing, more specific levels (e.g., netId.layerId) take precedence for nominal values, priors, etc.\nnominalValue [String \\| NUMERIC]: Specifies neural network nominal values. This can be:\nA PEtab variable that via the mapping table maps to an HDF5 file. If no file exists when the problem is imported and the parameters are set to be estimated, a file is created with randomly sampled values.\nA numeric value applied to all parameters under parameterId.\nestimate [0 \\| 1]: Indicates whether the parameters are estimated (1) or fixed (0). This must be consistent across layers. For example, if netId has estimate = 0, then potential layer rows must also be 0. In other words, freezing individual network parameters is not allowed.\ninitializationPriorType [String, OPTIONAL]: Specifies the prior used for sampling initial values before parameter estimation. In addition to the PEtab-supported priors [ADD], the SciML extension supports the following standard neural network initialization priors:\nkaimingUniform (default) — with gain as initializationPriorParameters value.\nkaimingNormal — with gain as initializationPriorParameters value.\nxavierUniform — with gain as initializationPriorParameters value.\nxavierNormal — with gain as initializationPriorParameters value.","category":"page"},{"location":"format.html#Different-Priors-for-Different-Layers","page":"Format","title":"Different Priors for Different Layers","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Different layers can have distinct initialization prior parameters. For example, consider a neural-network model net1 where layer1 and layer2 require different initializationPriorParameters because they use different activation functions that need distinct gain values for the kaimingUniform prior. A valid parameter table would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"parameterId parameterScale lowerBound upperBound estimate nominalValue initializationPriorType initializationPriorParameters\nnet1_ps lin -inf inf 1 net1_ps_file kaimingUniform 1\nnet1_layer1_ps lin -inf inf 1 net1_ps_file kaimingUniform 1\nnet1_layer2_ps lin -inf inf 1 net1_ps_file kaimingUniform 5/3","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Where parameterId are assumed to have been properly assigned in the mapping table. In this example, each layer references the same file variable for nominalValue. This means the layers obtain their values from the specified file. Unless a numeric value is provided for nominalValue, referring to the same file is required, since all neural network parameters should be collected in a single HDF5 file following the structure described here.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"It is also possible to specify different priors for different parameter arrays within a layer. For example, to use different priors for the weights and bias in layer1 of net1 (assuming a linear layer), a valid parameter table would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"parameterId parameterScale lowerBound upperBound estimate nominalValue initializationPriorType initializationPriorParameters\nnet1_ps lin -inf inf 1 net1_ps_file kaimingUniform 1\nnet1_layer1_weight lin -inf inf 1 net1_ps_file kaimingUniform 1\nnet1_layer1_bias lin -inf inf 1 net1_ps_file kaimingNormal 5/3","category":"page"},{"location":"format.html#Bounds-for-neural-net-parameters","page":"Format","title":"Bounds for neural net parameters","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Bounds can be specified for an entire network or its nested levels. However, it should be noted that most optimization algorithms used for neural networks, such as ADAM, do not support parameter bounds in their standard implementation.","category":"page"},{"location":"format.html#Problem-YAML-File","page":"Format","title":"Problem YAML File","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The PEtab problem YAML file follows the format of PEtab version 2, except that a mapping table is now required (it is optional in the standard). It also includes an extension section for specifying neural network YAML files:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"extensions:\n  petab_sciml:\n    netId1:\n      file: \"file_path1.yaml\"\n    netId2:\n      file: \"file_path2.yaml\"","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Here, netId1 and netId2 are the IDs of the neural network models. If the neural network is provided in another format—typically one specific to a certain implementation—the neural network library should be provided to inform users which library is used. For example, when using Lux.jl in Julia, a valid file would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"extensions:\n  petab_sciml:\n    netId1:\n      library: \"Lux.jl\"\n    netId2:\n      library: \"Lux.jl\"","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"It is then up to the specific implementation to provide the neural network model during import.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Any number of neural networks can be specified. For example, for a model with a single neural network with ID net1, a valid YAML file would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"format_version: 2\nproblems:\n  - model_files:\n      model_sbml:\n        location: \"model.xml\"\n        language: \"sbml\"\n    measurement_files:\n      - \"measurements.tsv\"\n    observable_files:\n      - \"observables.tsv\"\n    condition_files:\n      - \"conditions.tsv\"\n    mapping_files:\n      - \"mapping_table.tsv\"\nparameter_file: \"parameters.tsv\"\nextensions:\n  petab_sciml:\n    net1:\n      file: \"net1.yaml\"","category":"page"},{"location":"index.html#PEtab-SciML-Extension","page":"Home","title":"PEtab SciML Extension","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"The PEtab SciML extension expands the PEtab standard for parameter estimation problems to support hybrid models that combine data-driven neural network models with a mechanistic Ordinary Differential Equation (ODE) model. This enables a reproducible format for specifying and ultimately fitting hybrid models to time-lapse data. This repository contains both the format specification and a Python library for exporting neural network models to a standard YAML format, which can be imported across multiple programming languages.","category":"page"},{"location":"index.html#Major-Highlights","page":"Home","title":"Major Highlights","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"A format which supports three approaches for combining mechanistic and neural network models:\nIncorporating neural network model(s) data-driven model in the ODE model right-hand side.\nIncorporating neural network model(s) in the observable formula which describes the mapping between simulation output and measurement data.\nIncorporating neural network model(s) to set constant model parameter values prior to simulation, allowing for example, available metadata to be used to set parameter values.\nFormat which supports many neural network architectures, including most standard layers and activation functions available in packages such as PyTorch.\nFormat supported in tools across several programming languages. In particular, both PEtab.jl in Julia and AMICI in Python (Jax) can import problems in the PEtab SciML format.\nAn extensive test suite that ensures the correctness of tools supporting the format.","category":"page"},{"location":"index.html#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"TODO: Dilan please help here. Will need to setup with pip?","category":"page"},{"location":"index.html#Getting-help","page":"Home","title":"Getting help","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"If you have any problems with either using this package, or with creating a PEtab SciML problem, here are some helpful tips:","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"Please open an issue on GitHub.\nPost your questions in the #sciml-sysbio channel on the Julia Slack. While this is not a Julia package, the developers are active on that forum.","category":"page"},{"location":"tutorial.html#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial.html","page":"Tutorial","title":"Tutorial","text":"The tutorials will consist of:","category":"page"},{"location":"tutorial.html","page":"Tutorial","title":"Tutorial","text":"Overarching tutorial where we show how to Lotka-Voltera problem from the UDE paper.\nExtended tutorial 1 where we have a neural-network setting parameters, here it is also worthwhile to consider simulation conditions.\nExtended tutorial 2 where we have a neural network in the observable function.","category":"page"},{"location":"tutorial.html","page":"Tutorial","title":"Tutorial","text":"If time, add tutorial for having two neural networks.","category":"page"}]
}
